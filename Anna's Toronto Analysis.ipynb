{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Segmenting and Clustering Neighborhoods in Toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "_Anna A. Stepanova, Ph.D_"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Introduction"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this project, I will scrape the web data using a package *BeautifulSoup*. Then, I'll get the neighborhood information data from web, convert addresses into their equivalent latitude and longitude values. Also, I will use the Foursquare API to explore neighborhoods in Torono. I will use the **explore** function to get the most common venue categories in each neighborhood, and then use this feature to group the neighborhoods into clusters. I will use the *k*-means clustering algorithm to complete this task. Finally, I will use the Folium library to visualize the neighborhoods in Toronto and their emerging clusters."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Table of Contents\n\n\n1. [Scrape Wikipedia Page](#item1)\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's download required packages before we explore the data"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - folium=0.11.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n    folium-0.11.0              |             py_0          61 KB  conda-forge\n    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n    branca-0.4.1               |             py_0          26 KB  conda-forge\n    certifi-2020.6.20          |   py36h9f0ad1d_0         151 KB  conda-forge\n    ca-certificates-2020.6.20  |       hecda079_0         145 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         2.5 MB\n\nThe following NEW packages will be INSTALLED:\n\n    branca:          0.4.1-py_0        conda-forge\n    folium:          0.11.0-py_0       conda-forge\n    python_abi:      3.6-1_cp36m       conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2020.1.1-0                    --> 2020.6.20-hecda079_0     conda-forge\n    certifi:         2020.6.20-py36_0              --> 2020.6.20-py36h9f0ad1d_0 conda-forge\n    openssl:         1.1.1g-h7b6447c_0             --> 1.1.1g-h516909a_0        conda-forge\n\n\nDownloading and Extracting Packages\nopenssl-1.1.1g       | 2.1 MB    | ##################################### | 100% \nfolium-0.11.0        | 61 KB     | ##################################### | 100% \npython_abi-3.6       | 4 KB      | ##################################### | 100% \nbranca-0.4.1         | 26 KB     | ##################################### | 100% \ncertifi-2020.6.20    | 151 KB    | ##################################### | 100% \nca-certificates-2020 | 145 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nLibraries imported.\n"
                }
            ],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\n#from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.11.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nfrom bs4 import BeautifulSoup # web scrapping library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"item1\"></a>\n### 1. Scrape Wikipedia Page"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's build the code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes, boroughs and neighborhoods.\nWe'll use BeautifulSoup library to extract the table from the web-page."
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": "# import the library we use to open URLs\nimport urllib.request\n\n# specify the URL of the Wikipedia page page we are going to be scraping\nurl = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using the *urllib.request* library, we want to query the page and put the HTML data into a variable (which we have called \u2018url\u2019):"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "page = urllib.request.urlopen(url)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Then we use Beautiful Soup to parse the HTML data we stored in our \u2018url\u2019 variable and store it in a new variable called \u2018soup\u2019 in the Beautiful Soup format. We use the \u201clxml\u201d library option:"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "# parse the HTML from our URL into the BeautifulSoup parse tree format\nsoup = BeautifulSoup(page, \"lxml\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Extract the table data from the xml using class \"wikitable sortable\":"
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": "# find and extract table data from the Wikipedia page\ntable=soup.find('table', class_='wikitable sortable')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now that the table has been found, let's use BeautifulSoup to extract rows into 3 future columns. Then we'll use *pandas* to create a data frame. We will exclude cells with a borough that is **Not assigned** and reset the indexes in a modified data frame. \nLet's print first 12 rows"
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PostalCode</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M3A</td>\n      <td>North York</td>\n      <td>Parkwoods</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M4A</td>\n      <td>North York</td>\n      <td>Victoria Village</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Regent Park, Harbourfront</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M6A</td>\n      <td>North York</td>\n      <td>Lawrence Manor, Lawrence Heights</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M7A</td>\n      <td>Downtown Toronto</td>\n      <td>Queen's Park, Ontario Provincial Government</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>M9A</td>\n      <td>Etobicoke</td>\n      <td>Islington Avenue, Humber Valley Village</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>M1B</td>\n      <td>Scarborough</td>\n      <td>Malvern, Rouge</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>M3B</td>\n      <td>North York</td>\n      <td>Don Mills</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>M4B</td>\n      <td>East York</td>\n      <td>Parkview Hill, Woodbine Gardens</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>M5B</td>\n      <td>Downtown Toronto</td>\n      <td>Garden District, Ryerson</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>M6B</td>\n      <td>North York</td>\n      <td>Glencairn</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>M9B</td>\n      <td>Etobicoke</td>\n      <td>West Deane Park, Princess Gardens, Martin Grov...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   PostalCode            Borough  \\\n0        M3A\n        North York\n   \n1        M4A\n        North York\n   \n2        M5A\n  Downtown Toronto\n   \n3        M6A\n        North York\n   \n4        M7A\n  Downtown Toronto\n   \n5        M9A\n         Etobicoke\n   \n6        M1B\n       Scarborough\n   \n7        M3B\n        North York\n   \n8        M4B\n         East York\n   \n9        M5B\n  Downtown Toronto\n   \n10       M6B\n        North York\n   \n11       M9B\n         Etobicoke\n   \n\n                                         Neighborhood  \n0                                          Parkwoods\n  \n1                                   Victoria Village\n  \n2                          Regent Park, Harbourfront\n  \n3                   Lawrence Manor, Lawrence Heights\n  \n4        Queen's Park, Ontario Provincial Government\n  \n5            Islington Avenue, Humber Valley Village\n  \n6                                     Malvern, Rouge\n  \n7                                          Don Mills\n  \n8                    Parkview Hill, Woodbine Gardens\n  \n9                           Garden District, Ryerson\n  \n10                                         Glencairn\n  \n11  West Deane Park, Princess Gardens, Martin Grov...  "
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "### Let's get column data\n#Initialize the columns\nA=[]\nB=[]\nC=[]\n\n\nfor row in right_table.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells)==3:\n        A.append(cells[0].find(text=True))\n        B.append(cells[1].find(text=True))\n        C.append(cells[2].find(text=True))\n        \n#### Now let's create a data frame using pandas library\ntor=pd.DataFrame(A,columns=['PostalCode'])\ntor['Borough']=B\ntor['Neighborhood']=C\n\n\n# First filter out those rows which \n# does not contain any data \ntor = tor.dropna(how = 'all') \n\n### Drop rows Not assigned\ntor.drop(tor[tor['Borough'] == 'Not assigned\\n'].index, inplace = True)\n\n### print the data frame resetting the index\ntor.reset_index(drop=True, inplace = True)\n\n### Print the modified dataframe \ntor.head(12)\n     \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The dataframe consists of three columns: PostalCode, Borough, and Neighborhood and 103 entries for these columns."
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(103, 3)\n"
                }
            ],
            "source": "### print the shape of the data frame\nprint(tor.shape)\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}