{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Young Scientist in Search for the Dream City"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "_Anna A. Stepanova, Ph.D_"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"item1\"></a>\n## Introduction/Business Problem"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Here I present a Capstone Project for IBM Specialization.\n\nThe BioWiz University of Wonderland is organizing a job fair for BioTechMed School. In the preliminary survey of young scientists - graduate students and postdocs of the University, the Career Development Office identified a list of factors for choosing an ideal work location. By the time of the job fair, the office needs to prepare a review of the best cities suitable for young scientists and their families. It'll become a basis for the recommendation system that ranks the cities based on the respondent's requests and expectations.\nLet's review the list of factors. First of all, it should be a city known for its biotech or biomedical research. All affiliates of BioWiz U follow the best trends in education and recognize that physical activity matters not only for their health but for their creativity and work performance. Therefore, in general, respondents found essential dance studios, bike paths and shops, stadiums. Among recreational spots, the most common choice fell to theaters, museums, art galleries, and nightlife spots. For most respondents, the crime rate and availability of good preschools were crucial because they had families with kids. A group of respondents insisted on having a developed public transportation system. Non-essential yet popular requests were outdoors and recreations, scenic look-outs, trails, and spiritual centers. Respondents with certain health conditions were opposed to living in cities with hot and humid climates. \nDuring the job fair, BioWiz U will present their project, identify critical factors for choosing a dream city, and suggest ways to apply similar recommendation systems in other departments and universities. The latter will include the discussion of surveys, how to translate these data into a problem that can be solved by data scientists. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Table of Contents\n\n\n1. [Introduction/Business Problem](#item1)\n2. [Data](#item2)\n\n    2.1. [Crime Data](#item21)\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"item2\"></a>\n## Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The list of the cities best suited for biotechnology or biomedical research in Canada and the USA will be obtained from https://www.glassdoor.com/ from the \"Top Cities\" category and stored as a .csv file. Using **geopy** package, we'll find geographical cities' coordinates to use them with Foursquare API. Using Visual Crossing Weather API, we'll obtain historical weather data for chosen cities and store summarized results for the past five years in a .csv file for future access. Generalized crime rates data (crime index and safety index) for US and Canadian cities will be obtained by scraping https://www.numbeo.com/crime/. Finally, using Foursquare API, we'll search specific categories of venues (Arts & Entertainment, Country Dance Club, Music Venue, Dance Studio, Stadium, Rock Climbing Spot, Nightlife Spot, Outdoors & Recreation, Bike Trail, Preschool, Spiritual Center, Travel & Transport, Scenic Lookout, Trail).\nWe'll search for venues within city limits.\n\n\nHaving gathered all the required data, we'll address the following objectives:\n\n\n1) We'll cluster cities to identify overall similarities between them based on crime and weather data;\n\n2) We'll cluster cities based on venue selections;\n\n3) (OPTIONAL) We'll generate a fake survey dataset (set of preferences for choosing a dream city) and try to build a recommendation system allowing us to match a particular respondent with the list of best-matched cities."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "***\nLet's download required packages before we explore the data"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: geopy in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.18.1)\nRequirement already satisfied: geographiclib<2,>=1.49 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geopy) (1.49)\nCollecting folium\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f0/44e69d50519880287cc41e7c8a6acc58daa9a9acf5f6afc52bcc70f69a6d/folium-0.11.0-py2.py3-none-any.whl (93kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 9.5MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (1.15.4)\nCollecting branca>=0.3.0 (from folium)\n  Downloading https://files.pythonhosted.org/packages/13/fb/9eacc24ba3216510c6b59a4ea1cd53d87f25ba76237d7f4393abeaf4c94e/branca-0.4.1-py3-none-any.whl\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.21.0)\nRequirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.10)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (1.24.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2020.6.20)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2.8)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jinja2>=2.9->folium) (1.1.0)\nInstalling collected packages: branca, folium\nSuccessfully installed branca-0.4.1 folium-0.11.0\nLibraries imported.\n"
                }
            ],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\n#!pip install --user pandas==1.0.3\n\nimport pandas as pd # library for data analsysis\n\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n!pip install geopy\n# uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!pip install folium \n# uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nfrom bs4 import BeautifulSoup # web scrapping library\n\n#import plotting libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nimport seaborn as sns\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"item21\"></a>\n### 2.1. Crime Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this section, we'll scrape web data from https://www.numbeo.com/crime/, in order to obtain crime data for the USA and Canada that is in the table of cities, crime index, safety index.\nWe'll use _BeautifulSoup_ library to extract the table from the web-page.\n***\nLet's write a function that takes url as an argument and returns a data frame containing City, Crime Index, and Safety Index columns:"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "def crime_table(url):\n    # this function will extracti a crime table from https://www.numbeo.com/crime/ using url for specific country\n    # arguments: urt\n    # return: a data frame containing City, Crime Index, and Safety Index columns\n    \n    \n    # import the library we use to open URLs\n    import urllib.request\n    \n    page = urllib.request.urlopen(url)\n    \n    # parse the HTML from our URL into the BeautifulSoup parse tree format\n    soup = BeautifulSoup(page, \"lxml\")\n    \n    # find the table with cities and crime/safety indices\n    table = soup.find('table', class_=\"stripe row-border order-column compact\")\n    \n    \n    #Step 2: create a data frame\n    ### Let's get column data\n    #Initialize the columns\n    A=[]\n    B=[]\n    C=[]\n\n\n    for row in table.findAll('tr'):\n        cells=row.findAll('td')\n        if len(cells)==4:\n            A.append(cells[1].find(text=True))\n            B.append(cells[2].find(text=True))\n            C.append(cells[3].find(text=True))\n\n    #### Now let's create a data frame using pandas library\n    crime=pd.DataFrame(A,columns=['City'])\n    crime['Crime Index']=B\n    crime['Safety Index']=C\n    \n    return(crime)\n    \n    \n    "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we can set URLs for Canada and the United States to get desired data sets."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "# Canada Crime Data URL\n# specify the URL of the web page page we are going to be scraping\nca_url = \"https://www.numbeo.com/crime/country_result.jsp?country=Canada\"\n\n## US Crime Data URL\n# specify the URL of the web page page we are going to be scraping\nus_url = \"https://www.numbeo.com/crime/country_result.jsp?country=United+States\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Applying _crime_table_ function we can retrive crime data from the web. After creating separate data frames, let's combine them and check dimentions of a new data frame as well as its first and last 10 entries."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(85, 4)\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>Crime Index</th>\n      <th>Safety Index</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Surrey</td>\n      <td>61.30</td>\n      <td>38.70</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Red Deer</td>\n      <td>60.23</td>\n      <td>39.77</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Winnipeg</td>\n      <td>57.20</td>\n      <td>42.80</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Regina</td>\n      <td>56.12</td>\n      <td>43.88</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brampton</td>\n      <td>55.61</td>\n      <td>44.39</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Kelowna</td>\n      <td>50.21</td>\n      <td>49.79</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oshawa</td>\n      <td>50.03</td>\n      <td>49.97</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Hamilton</td>\n      <td>49.83</td>\n      <td>50.17</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Saskatoon</td>\n      <td>49.40</td>\n      <td>50.60</td>\n      <td>Canada</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Nanaimo, BC</td>\n      <td>46.45</td>\n      <td>53.55</td>\n      <td>Canada</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "          City Crime Index Safety Index Country\n0       Surrey       61.30        38.70  Canada\n1     Red Deer       60.23        39.77  Canada\n2     Winnipeg       57.20        42.80  Canada\n3       Regina       56.12        43.88  Canada\n4     Brampton       55.61        44.39  Canada\n5      Kelowna       50.21        49.79  Canada\n6       Oshawa       50.03        49.97  Canada\n7     Hamilton       49.83        50.17  Canada\n8    Saskatoon       49.40        50.60  Canada\n9  Nanaimo, BC       46.45        53.55  Canada"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Canada Crime Data \nca_crime = crime_table(ca_url)\nca_crime['Country'] = \"Canada\"\n\n# US Crime Data\nus_crime = crime_table(us_url)\nus_crime['Country'] = \"USA\"\n\n\n# Combine data frames into a single table\ncrime_df = ca_crime.append(us_crime, ignore_index = True)\n\nprint(crime_df.shape)\ncrime_df.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City</th>\n      <th>Crime Index</th>\n      <th>Safety Index</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75</th>\n      <td>Boise, ID</td>\n      <td>37.46</td>\n      <td>62.54</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Brooklyn, NY</td>\n      <td>37.44</td>\n      <td>62.56</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>San Diego, CA</td>\n      <td>36.40</td>\n      <td>63.60</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Boston, MA</td>\n      <td>35.52</td>\n      <td>64.48</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>Austin, TX</td>\n      <td>34.12</td>\n      <td>65.88</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>Raleigh, NC</td>\n      <td>33.83</td>\n      <td>66.17</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>Salt Lake City, UT</td>\n      <td>31.76</td>\n      <td>68.24</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>El Paso, TX</td>\n      <td>31.13</td>\n      <td>68.87</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>Madison, WI</td>\n      <td>31.11</td>\n      <td>68.89</td>\n      <td>USA</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>Irvine, CA</td>\n      <td>19.12</td>\n      <td>80.88</td>\n      <td>USA</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                  City Crime Index Safety Index Country\n75           Boise, ID       37.46        62.54     USA\n76        Brooklyn, NY       37.44        62.56     USA\n77       San Diego, CA       36.40        63.60     USA\n78          Boston, MA       35.52        64.48     USA\n79          Austin, TX       34.12        65.88     USA\n80         Raleigh, NC       33.83        66.17     USA\n81  Salt Lake City, UT       31.76        68.24     USA\n82         El Paso, TX       31.13        68.87     USA\n83         Madison, WI       31.11        68.89     USA\n84          Irvine, CA       19.12        80.88     USA"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "crime_df.tail(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}